{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "friendly-cabin",
   "metadata": {},
   "source": [
    "# Lecture 4: strings\n",
    "\n",
    "## making strings, quotes, escaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ready-technical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a string this is another string\n"
     ]
    }
   ],
   "source": [
    "one = 'this is a string'\n",
    "two = \"this is another string\"\n",
    "\n",
    "print(one, two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "toxic-primary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ed's class is listening\n"
     ]
    }
   ],
   "source": [
    "quoted_string = \"ed's class is listening\"\n",
    "print(quoted_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "premier-reverse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ed's quote is \"escape characters\"\n"
     ]
    }
   ],
   "source": [
    "quoted_string = 'ed\\'s quote is \"escape characters\"'\n",
    "print(quoted_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prerequisite-engine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the escape character is \\\n"
     ]
    }
   ],
   "source": [
    "another_string = 'the escape character is \\\\'\n",
    "print(another_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "excessive-keeping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ed's quote is \"escape characters\"\n"
     ]
    }
   ],
   "source": [
    "quoted_string = \"ed's quote is \" + '\"escape characters\"'\n",
    "print(quoted_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "improved-schedule",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ed's quote is \"escape characters\" \n",
      "and new lines\n",
      "and more\n"
     ]
    }
   ],
   "source": [
    "quoted_string = \"\"\"ed's quote is \"escape characters\" \n",
    "and new lines\n",
    "and more\"\"\"\n",
    "\n",
    "print(quoted_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-auction",
   "metadata": {},
   "source": [
    "## putting variables in strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "assumed-printing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice is 18\n"
     ]
    }
   ],
   "source": [
    "age = 18\n",
    "name = \"Alice\"\n",
    "\n",
    "print(name + \" is \" + str(age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "still-challenge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice is 18\n"
     ]
    }
   ],
   "source": [
    "print(f'{name} is {age}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afraid-marking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Alice'\n"
     ]
    }
   ],
   "source": [
    "print(f'{name=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-jesus",
   "metadata": {},
   "source": [
    "## sorted(), encoding and order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "special-roommate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'I',\n",
       " 'a',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'd',\n",
       " 'd',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'j',\n",
       " 'k',\n",
       " 'n',\n",
       " 'n',\n",
       " 'n',\n",
       " 'n',\n",
       " 'n',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'p',\n",
       " 'p',\n",
       " 'p',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'u',\n",
       " 'y',\n",
       " 'y']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I opened jupyter notebook and typed a sentence\"\n",
    "\n",
    "sorted(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rotary-marriage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "normal-mailing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'banana', 'four', 'one', 'zebra']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['one', 'four', 'apple', 'zebra', 'banana']\n",
    "sorted(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-ordering",
   "metadata": {},
   "source": [
    "## lower, upper, title, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "typical-journalism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abdh Ahahbahj Dbahdbahasu Haakj Iuabsf\n"
     ]
    }
   ],
   "source": [
    "weird_string = \"ABDH AhahBAhj dbahdbahasu haAKJ iuABSF\"\n",
    "print(weird_string.title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dated-queen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple', 'Banana', 'Four', 'One', 'Rhino', 'Zebra']\n"
     ]
    }
   ],
   "source": [
    "# I want to sort these in intuitive alphabetical order.\n",
    "# convert them all to the same case.  lower upper title\n",
    "\n",
    "words = ['One', 'four', 'apple', 'Zebra', 'Banana', 'Rhino']\n",
    "\n",
    "for index in range(0,len(words)):\n",
    "    words[index] = words[index].title()\n",
    "\n",
    "words.sort()\n",
    "print(words)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-restoration",
   "metadata": {},
   "source": [
    "## replace \n",
    "\n",
    "(and string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "thrown-deadline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who's going to say, or eat, \"cheese\" -- the dairy product?\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Who\\'s going to say, or eat, \"cheese\" -- the dairy product?'\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "confident-ceremony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whos going to say or eat cheese  the dairy product\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "\n",
    "for mark in punctuation:\n",
    "    # print('replacing: ' + mark)\n",
    "    sentence = sentence.replace(mark, '')\n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "recent-fleece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whos going to say or eat cheese  the dairy product\n"
     ]
    }
   ],
   "source": [
    "newstring = ''\n",
    "for item in sentence:\n",
    "    if item.isalpha() or item == ' ':\n",
    "        newstring = newstring + item\n",
    "print(newstring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-disabled",
   "metadata": {},
   "source": [
    "## in, index, find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "informal-gates",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like to eat apples and bananas and pears and strawberries and cake\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I like to eat apples and bananas and pears and strawberries and cake\"\n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sought-freight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'pineapple' in sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "advisory-czech",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "substring not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-401e8f83d597>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pineapple'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: substring not found"
     ]
    }
   ],
   "source": [
    "sentence.index('pineapple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "precious-endorsement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.find('pineapple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-sculpture",
   "metadata": {},
   "source": [
    "## splitting and joining strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "particular-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I like to eat apples and bananas and pears and strawberries and cake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "pressed-favorite",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sentence.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "electric-elevation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'like', 'to', 'eat', 'apples', 'and', 'bananas', 'and', 'pears', 'and', 'strawberries', 'and', 'cake']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "spectacular-indiana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I like to eat apples and bananas and pears and strawberries and cake'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "coordinated-narrative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-oklahoma",
   "metadata": {},
   "source": [
    "# Hard example\n",
    "\n",
    "Let's count the unique words in the poem below.   \n",
    "\n",
    "Later we will learn to use *dictionaries* to make this easier, but for now, we will sort and count.\n",
    "\n",
    "Specifically we will:\n",
    "1. extract all the lowercase words\n",
    "2. split them into a list\n",
    "3. sort the list\n",
    "4. iterate through the list to count the number of times each unique word appeared\n",
    "5. store the results in a new list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "satisfied-corruption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Two roads diverged in a yellow wood,\n",
      "And sorry I could not travel both\n",
      "And be one traveler, long I stood\n",
      "And looked down one as far as I could\n",
      "To where it bent in the undergrowth;\n",
      "\n",
      "Then took the other, as just as fair,\n",
      "And having perhaps the better claim,\n",
      "Because it was grassy and wanted wear;\n",
      "Though as for that the passing there\n",
      "Had worn them really about the same,\n",
      "\n",
      "And both that morning equally lay\n",
      "In leaves no step had trodden black.\n",
      "Oh, I kept the first for another day!\n",
      "Yet knowing how way leads on to way,\n",
      "I doubted if I should ever come back.\n",
      "\n",
      "I shall be telling this with a sigh\n",
      "Somewhere ages and ages hence:\n",
      "Two roads diverged in a wood, and I—\n",
      "I took the one less traveled by,\n",
      "And that has made all the difference.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "frost = \"\"\"\n",
    "Two roads diverged in a yellow wood,\n",
    "And sorry I could not travel both\n",
    "And be one traveler, long I stood\n",
    "And looked down one as far as I could\n",
    "To where it bent in the undergrowth;\n",
    "\n",
    "Then took the other, as just as fair,\n",
    "And having perhaps the better claim,\n",
    "Because it was grassy and wanted wear;\n",
    "Though as for that the passing there\n",
    "Had worn them really about the same,\n",
    "\n",
    "And both that morning equally lay\n",
    "In leaves no step had trodden black.\n",
    "Oh, I kept the first for another day!\n",
    "Yet knowing how way leads on to way,\n",
    "I doubted if I should ever come back.\n",
    "\n",
    "I shall be telling this with a sigh\n",
    "Somewhere ages and ages hence:\n",
    "Two roads diverged in a wood, and I—\n",
    "I took the one less traveled by,\n",
    "And that has made all the difference.\n",
    "\"\"\"\n",
    "print(frost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "desperate-testimony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 'about'], [1, 'all'], [1, 'another'], [1, 'back'], [1, 'because'], [1, 'bent'], [1, 'better'], [1, 'black'], [1, 'by'], [1, 'claim'], [1, 'come'], [1, 'day'], [1, 'difference'], [1, 'doubted'], [1, 'down'], [1, 'equally'], [1, 'ever'], [1, 'fair'], [1, 'far'], [1, 'first'], [1, 'grassy'], [1, 'has'], [1, 'having'], [1, 'hence'], [1, 'how'], [1, 'if'], [1, 'just'], [1, 'kept'], [1, 'knowing'], [1, 'lay'], [1, 'leads'], [1, 'leaves'], [1, 'less'], [1, 'long'], [1, 'looked'], [1, 'made'], [1, 'morning'], [1, 'no'], [1, 'not'], [1, 'oh'], [1, 'on'], [1, 'other'], [1, 'passing'], [1, 'perhaps'], [1, 'really'], [1, 'same'], [1, 'shall'], [1, 'should'], [1, 'sigh'], [1, 'somewhere'], [1, 'sorry'], [1, 'step'], [1, 'stood'], [1, 'telling'], [1, 'them'], [1, 'then'], [1, 'there'], [1, 'this'], [1, 'though'], [1, 'travel'], [1, 'traveled'], [1, 'traveler'], [1, 'trodden'], [1, 'undergrowth'], [1, 'wanted'], [1, 'was'], [1, 'wear'], [1, 'where'], [1, 'with'], [1, 'worn'], [1, 'yellow'], [1, 'yet'], [2, 'ages'], [2, 'be'], [2, 'both'], [2, 'could'], [2, 'diverged'], [2, 'for'], [2, 'had'], [2, 'it'], [2, 'roads'], [2, 'to'], [2, 'took'], [2, 'two'], [2, 'way'], [2, 'wood'], [3, 'a'], [3, 'one'], [3, 'that'], [4, 'in'], [5, 'as'], [8, 'the'], [9, 'and'], [9, 'i']]\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "# convert to lowercase?\n",
    "frost = frost.lower()\n",
    "# get rid of newline\n",
    "frost = frost.replace('\\n', ' ')\n",
    "# remove punctuation\n",
    "for mark in punctuation:\n",
    "    frost = frost.replace(mark,'')\n",
    "\n",
    "frost = frost.replace('—', '')\n",
    "\n",
    "# split on ' '\n",
    "words = frost.split(' ')\n",
    "\n",
    "# count these words\n",
    "unique_words = dict()\n",
    "\n",
    "for word in words:\n",
    "    if word != '':\n",
    "        if word not in unique_words:\n",
    "            unique_words[word] = 1\n",
    "        else:\n",
    "            unique_words[word] = unique_words[word] + 1\n",
    "    \n",
    "#print(unique_words)\n",
    "    \n",
    "word_counts = []\n",
    "for key in unique_words:\n",
    "    word_counts.append([unique_words[key], key])\n",
    "\n",
    "word_counts.sort()\n",
    "print(word_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-patio",
   "metadata": {},
   "source": [
    "# how to count unique items?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "spatial-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Alice', 'Bob', 'Carol', 'Bob', 'James', 'Joan', 'Alice', 'Bob', 'Joan']\n",
    "\n",
    "# we want a list of lists: [[2, 'Alice'], [3, 'Bob'], [1, 'Carol'], [1, 'James'], [2, 'Joan']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-planet",
   "metadata": {},
   "source": [
    "## approach 1:\n",
    "\n",
    "sort list, loop through list and count repetitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "vocal-hypothesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice  0\n",
      "Alice Alice 1\n",
      "Bob Alice 2\n",
      "Bob Bob 1\n",
      "Bob Bob 2\n",
      "Carol Bob 3\n",
      "James Carol 1\n",
      "Joan James 1\n",
      "Joan Joan 1\n",
      "#END Joan 2\n",
      "[[2, 'Alice'], [3, 'Bob'], [1, 'Carol'], [1, 'James'], [2, 'Joan']]\n"
     ]
    }
   ],
   "source": [
    "names.sort()\n",
    "\n",
    "unique = []\n",
    "\n",
    "prev = ''\n",
    "count = 0\n",
    "\n",
    "for name in names + ['#END']: \n",
    "    print(name, prev, count)\n",
    "    if name == prev:\n",
    "        count = count + 1\n",
    "    else:\n",
    "        if count > 0:\n",
    "            unique.append([count, prev])\n",
    "        count = 1\n",
    "        prev = name\n",
    "\n",
    "print(unique)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-commons",
   "metadata": {},
   "source": [
    "## approach 2\n",
    "\n",
    "use a dictionary. (which we will cover in more detail later), use name as key for dictionary, and increment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "defined-sewing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Alice': 2, 'Bob': 3}\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "name_counts = dict()\n",
    "\n",
    "name_counts['Alice'] = 2\n",
    "name_counts['Bob'] = 3\n",
    "\n",
    "print(name_counts)\n",
    "\n",
    "print('Carol' in name_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "opponent-valentine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Alice': 2, 'Bob': 3, 'Carol': 1, 'James': 1, 'Joan': 2}\n"
     ]
    }
   ],
   "source": [
    "name_counts = dict()\n",
    "\n",
    "for name in names:\n",
    "    #print(name)\n",
    "    if name not in name_counts:\n",
    "        name_counts[name] = 1\n",
    "    else:\n",
    "        name_counts[name] = name_counts[name] + 1\n",
    "    #print(name_counts)\n",
    "    \n",
    "print(name_counts)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "increasing-dinner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Alice': 2, 'Bob': 3, 'Carol': 1, 'James': 1, 'Joan': 2}\n"
     ]
    }
   ],
   "source": [
    "print(name_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-institute",
   "metadata": {},
   "source": [
    "Then convert dictionary to the list we wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "sized-segment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 'Alice'], [3, 'Bob'], [1, 'Carol'], [1, 'James'], [2, 'Joan']]\n"
     ]
    }
   ],
   "source": [
    "unique = []\n",
    "\n",
    "for key in name_counts:\n",
    "    # print(key, name_counts[key])\n",
    "    unique.append([name_counts[key], key])\n",
    "    \n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-fleece",
   "metadata": {},
   "source": [
    "## approach 3:\n",
    "\n",
    "use Counter object from collections, which is a dictionary that does the counting for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "exciting-egypt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Bob': 3, 'Alice': 2, 'Joan': 2, 'Carol': 1, 'James': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "name_counter = Counter(names)\n",
    "\n",
    "print(name_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-bradford",
   "metadata": {},
   "source": [
    "Then convert to the list format we wanted, as we did for dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "authentic-education",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 'Alice'], [3, 'Bob'], [1, 'Carol'], [1, 'James'], [2, 'Joan']]\n"
     ]
    }
   ],
   "source": [
    "unique = []\n",
    "\n",
    "for key in name_counter:\n",
    "    # print(key, name_counts[key])\n",
    "    unique.append([name_counter[key], key])\n",
    "    \n",
    "print(unique)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}